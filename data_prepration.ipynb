{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unified Class Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "root_dir = \"datasets\"  # replace with your root directory path\n",
    "\n",
    "# ------------------------------------\n",
    "# Class Mappings (normalize class names)\n",
    "# ------------------------------------\n",
    "class_mapping = {\n",
    "    \"Tomato Early blight leaf\": \"Early_blight\",\n",
    "    \"Tomato_Early_blight\": \"Early_blight\",\n",
    "\n",
    "    \"Tomato Septoria leaf spot\": \"Septoria_leaf_spot\",\n",
    "    \"Tomato_Septoria_leaf_spot\": \"Septoria_leaf_spot\",\n",
    "\n",
    "    \"Tomato leaf bacterial spot\": \"Bacterial_spot\",\n",
    "    \"Tomato_Bacterial_spot\": \"Bacterial_spot\",\n",
    "    \"Bacterial spot\": \"Bacterial_spot\",\n",
    "\n",
    "    \"Tomato leaf late blight\": \"Late_blight\",\n",
    "    \"Tomato_Late_blight\": \"Late_blight\",\n",
    "    \"Late blight\": \"Late_blight\",\n",
    "\n",
    "    \"Tomato mold leaf\": \"Leaf_Mold\",\n",
    "    \"Tomato_Leaf_Mold\": \"Leaf_Mold\",\n",
    "    \"Black mold\": \"Leaf_Mold\",\n",
    "\n",
    "    \"Tomato leaf mosaic virus\": \"Mosaic_virus\",\n",
    "    \"Tomato__Tomato_mosaic_virus\": \"Mosaic_virus\",\n",
    "\n",
    "    \"Tomato leaf yellow virus\": \"Yellow_Leaf_Curl_Virus\",\n",
    "    \"Tomato__Tomato_YellowLeaf__Curl_Virus\": \"Yellow_Leaf_Curl_Virus\",\n",
    "\n",
    "    \"Tomato__Target_Spot\": \"Target_Spot\",\n",
    "\n",
    "    \"Tomato_Spider_mites_Two_spotted_spider_mite\": \"Spider_mites\",\n",
    "\n",
    "    \"Tomato_healthy\": \"Healthy\",\n",
    "    \"health\": \"Healthy\",\n",
    "\n",
    "    \"Gray spot\": \"Gray_spot\",\n",
    "    \"powdery mildew\": \"Powdery_mildew\"\n",
    "}\n",
    "\n",
    "# Reverse mapping: unified class â†’ original classes\n",
    "unified_to_original = defaultdict(list)\n",
    "for orig, unified in class_mapping.items():\n",
    "    unified_to_original[unified].append(orig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unmapped class: PlantDoc-Combined/Tomato leaf\n",
      "âœ… Combined dataset created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create combined dataset directory\n",
    "combined_dir = os.path.join(root_dir, \"combined_dataset\")\n",
    "os.makedirs(combined_dir, exist_ok=True)\n",
    "\n",
    "# Traverse through datasets\n",
    "for dataset_name in os.listdir(root_dir):\n",
    "    dataset_path = os.path.join(root_dir, dataset_name)\n",
    "    if not os.path.isdir(dataset_path) or dataset_name == \"combined_dataset\":\n",
    "        continue\n",
    "\n",
    "    for orig_class in os.listdir(dataset_path):\n",
    "        orig_class_path = os.path.join(dataset_path, orig_class)\n",
    "        if not os.path.isdir(orig_class_path):\n",
    "            continue\n",
    "\n",
    "        # Check if this class has a mapping\n",
    "        if orig_class not in class_mapping:\n",
    "            print(f\"Skipping unmapped class: {dataset_name}/{orig_class}\")\n",
    "            continue\n",
    "\n",
    "        unified_class = class_mapping[orig_class]\n",
    "        class_out_dir = os.path.join(combined_dir, unified_class)\n",
    "        os.makedirs(class_out_dir, exist_ok=True)\n",
    "\n",
    "        for fname in os.listdir(orig_class_path):\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
    "                src_path = os.path.join(orig_class_path, fname)\n",
    "                # âœ… New format: datasetname_unifiedclassname_fname\n",
    "                new_fname = f\"{dataset_name}_{unified_class}_{fname}\"\n",
    "                dst_path = os.path.join(class_out_dir, new_fname)\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "\n",
    "print(\"âœ… Combined dataset created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">skipped PlantDoc-Combined/Tomato leaf as we dont know these are healthy leaves or diseased ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of images in each class of Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow_Leaf_Curl_Virus: 3283\n",
      "Bacterial_spot: 2344\n",
      "Late_blight: 2118\n",
      "Septoria_leaf_spot: 1919\n",
      "Healthy: 1697\n",
      "Spider_mites: 1676\n",
      "Target_Spot: 1404\n",
      "Leaf_Mold: 1110\n",
      "Early_blight: 1083\n",
      "Mosaic_virus: 427\n",
      "Powdery_mildew: 157\n",
      "Gray_spot: 84\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your merged dataset\n",
    "combined_dir = os.path.join(root_dir, \"combined_dataset\")\n",
    "\n",
    "class_counts = Counter()\n",
    "\n",
    "for class_name in os.listdir(combined_dir):\n",
    "    class_dir = os.path.join(combined_dir, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    \n",
    "    num_images = len([\n",
    "        f for f in os.listdir(class_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))\n",
    "    ])\n",
    "    class_counts[class_name] = num_images\n",
    "\n",
    "# Print class counts sorted by size\n",
    "for cls, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{cls}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Removing Spider Mite as it is a pest infection not a disease\n",
    "> Removing Powdery_mildew and Gray_Spot as they are unique classes that exists in only one dataset and they have very few number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted folder: datasets\\combined_dataset\\Spider_mites\n",
      "Deleted folder: datasets\\combined_dataset\\Powdery_mildew\n",
      "Deleted folder: datasets\\combined_dataset\\Gray_spot\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "# List of classes to remove\n",
    "remove_classes = [\"Spider_mites\", \"Powdery_mildew\", \"Gray_spot\"]\n",
    "\n",
    "for cls in remove_classes:\n",
    "\tfolder_path = os.path.join(combined_dir, cls)\n",
    "\tif os.path.isdir(folder_path):\n",
    "\t\tshutil.rmtree(folder_path)\n",
    "\t\tprint(f\"Deleted folder: {folder_path}\")\n",
    "\telse:\n",
    "\t\tprint(f\"Folder not found (skipped): {folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Checking if the folders successfully deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow_Leaf_Curl_Virus: 3283\n",
      "Bacterial_spot: 2344\n",
      "Late_blight: 2118\n",
      "Septoria_leaf_spot: 1919\n",
      "Healthy: 1697\n",
      "Target_Spot: 1404\n",
      "Leaf_Mold: 1110\n",
      "Early_blight: 1083\n",
      "Mosaic_virus: 427\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your merged dataset\n",
    "combined_dir = os.path.join(root_dir, \"combined_dataset\")\n",
    "\n",
    "class_counts = Counter()\n",
    "\n",
    "for class_name in os.listdir(combined_dir):\n",
    "    class_dir = os.path.join(combined_dir, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    \n",
    "    num_images = len([\n",
    "        f for f in os.listdir(class_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))\n",
    "    ])\n",
    "    class_counts[class_name] = num_images\n",
    "\n",
    "# Print class counts sorted by size\n",
    "for cls, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{cls}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Balancing with same distributions of images from each dataset\n",
    "> For classes greater than 2000 , we are downsampling to 2000 images with same distributon of dataset.\n",
    "> For classes less than 2000 images, we are augmenting to 2000 images, augmnted images distribution w.r.t datasets is same as in before augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‚ Processing class: Bacterial_spot\n",
      "  Before processing:\n",
      "    PlantDoc-Combined: 107 (4.56%)\n",
      "    PlantVillage: 2127 (90.74%)\n",
      "    taiwan: 110 (4.69%)\n",
      "  After processing:\n",
      "    PlantDoc-Combined: 91 (4.55%)\n",
      "    PlantVillage: 1815 (90.75%)\n",
      "    taiwan: 94 (4.70%)\n",
      "\n",
      "ðŸ“‚ Processing class: Early_blight\n",
      "  Before processing:\n",
      "    PlantDoc-Combined: 83 (7.66%)\n",
      "    PlantVillage: 1000 (92.34%)\n",
      "  Augmenting 917 images...\n",
      "  After processing:\n",
      "    PlantDoc-Combined: 153 (7.65%)\n",
      "    PlantVillage: 1847 (92.35%)\n",
      "\n",
      "ðŸ“‚ Processing class: Healthy\n",
      "  Before processing:\n",
      "    PlantVillage: 1591 (93.75%)\n",
      "    taiwan: 106 (6.25%)\n",
      "  Augmenting 303 images...\n",
      "  After processing:\n",
      "    PlantVillage: 1875 (93.75%)\n",
      "    taiwan: 125 (6.25%)\n",
      "\n",
      "ðŸ“‚ Processing class: Late_blight\n",
      "  Before processing:\n",
      "    PlantDoc-Combined: 111 (5.24%)\n",
      "    PlantVillage: 1909 (90.13%)\n",
      "    taiwan: 98 (4.63%)\n",
      "  After processing:\n",
      "    PlantDoc-Combined: 105 (5.25%)\n",
      "    PlantVillage: 1803 (90.15%)\n",
      "    taiwan: 92 (4.60%)\n",
      "\n",
      "ðŸ“‚ Processing class: Leaf_Mold\n",
      "  Before processing:\n",
      "    PlantDoc-Combined: 91 (8.20%)\n",
      "    PlantVillage: 952 (85.77%)\n",
      "    taiwan: 67 (6.04%)\n",
      "  Augmenting 890 images...\n",
      "  After processing:\n",
      "    PlantDoc-Combined: 164 (8.20%)\n",
      "    PlantVillage: 1715 (85.75%)\n",
      "    taiwan: 121 (6.05%)\n",
      "\n",
      "ðŸ“‚ Processing class: Mosaic_virus\n",
      "  Before processing:\n",
      "    PlantDoc-Combined: 54 (12.65%)\n",
      "    PlantVillage: 373 (87.35%)\n",
      "  Augmenting 1573 images...\n",
      "  After processing:\n",
      "    PlantDoc-Combined: 253 (12.65%)\n",
      "    PlantVillage: 1747 (87.35%)\n",
      "\n",
      "ðŸ“‚ Processing class: Septoria_leaf_spot\n",
      "  Before processing:\n",
      "    PlantDoc-Combined: 148 (7.71%)\n",
      "    PlantVillage: 1771 (92.29%)\n",
      "  Augmenting 81 images...\n",
      "  After processing:\n",
      "    PlantDoc-Combined: 154 (7.70%)\n",
      "    PlantVillage: 1846 (92.30%)\n",
      "\n",
      "ðŸ“‚ Processing class: Target_Spot\n",
      "  Before processing:\n",
      "    PlantVillage: 1404 (100.00%)\n",
      "  Augmenting 596 images...\n",
      "  After processing:\n",
      "    PlantVillage: 2000 (100.00%)\n",
      "\n",
      "ðŸ“‚ Processing class: Yellow_Leaf_Curl_Virus\n",
      "  Before processing:\n",
      "    PlantDoc-Combined: 75 (2.28%)\n",
      "    PlantVillage: 3208 (97.72%)\n",
      "  After processing:\n",
      "    PlantDoc-Combined: 46 (2.30%)\n",
      "    PlantVillage: 1954 (97.70%)\n",
      "\n",
      "âœ… Balanced dataset (all classes = 2000 images) created at: datasets/balanced_dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict, Counter\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# ---------------------------\n",
    "# Paths\n",
    "# ---------------------------\n",
    "root_dir = \"datasets/combined_dataset\"\n",
    "output_dir = \"datasets/balanced_dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Params\n",
    "# ---------------------------\n",
    "TARGET_SIZE = 2000\n",
    "random.seed(42)\n",
    "\n",
    "# ---------------------------\n",
    "# Augmentation pipeline (mild + realistic)\n",
    "# ---------------------------\n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomVerticalFlip(p=0.1),   # less frequent than horizontal\n",
    "\t\ttransforms.RandomPerspective(distortion_scale=0.1, p=0.3),  # mild warping\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    transforms.RandomResizedCrop(size=(224,224), scale=(0.9, 1.1)),  # mild zoom\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),  # small shifts\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "# ---------------------------\n",
    "# Helper: extract dataset name\n",
    "# ---------------------------\n",
    "def get_dataset_name(filename):\n",
    "    return filename.split(\"_\")[0]  # e.g., PlantVillage_earlyblight_xxx.jpg\n",
    "\n",
    "# ---------------------------\n",
    "# Helper: pretty print distributions\n",
    "# ---------------------------\n",
    "def print_distribution(title, dataset_groups, total):\n",
    "    print(f\"  {title}:\")\n",
    "    for ds, count in dataset_groups.items():\n",
    "        proportion = (count / total) * 100 if total > 0 else 0\n",
    "        print(f\"    {ds}: {count} ({proportion:.2f}%)\")\n",
    "\n",
    "# ---------------------------\n",
    "# Main loop\n",
    "# ---------------------------\n",
    "for class_name in os.listdir(root_dir):\n",
    "    class_path = os.path.join(root_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nðŸ“‚ Processing class: {class_name}\")\n",
    "    out_class_path = os.path.join(output_dir, class_name)\n",
    "    os.makedirs(out_class_path, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "\n",
    "    # Group by dataset\n",
    "    dataset_groups = defaultdict(list)\n",
    "    for f in files:\n",
    "        dataset_groups[get_dataset_name(f)].append(f)\n",
    "\n",
    "    total = len(files)\n",
    "    before_counts = {ds: len(imgs) for ds, imgs in dataset_groups.items()}\n",
    "    print_distribution(\"Before processing\", before_counts, total)\n",
    "\n",
    "    selected_files = []\n",
    "\n",
    "    # ---------------------------\n",
    "    # Case 1: >2000 â†’ Downsample\n",
    "    # ---------------------------\n",
    "    if total > TARGET_SIZE:\n",
    "        for ds, imgs in dataset_groups.items():\n",
    "            ratio = len(imgs) / total\n",
    "            k = round(ratio * TARGET_SIZE)\n",
    "            chosen = random.sample(imgs, min(k, len(imgs)))\n",
    "            selected_files.extend(chosen)\n",
    "\n",
    "        # Adjust rounding\n",
    "        if len(selected_files) > TARGET_SIZE:\n",
    "            selected_files = selected_files[:TARGET_SIZE]\n",
    "        elif len(selected_files) < TARGET_SIZE:\n",
    "            remaining = [f for f in files if f not in selected_files]\n",
    "            selected_files.extend(random.sample(remaining, TARGET_SIZE - len(selected_files)))\n",
    "\n",
    "        # Save directly\n",
    "        for f in selected_files:\n",
    "            shutil.copy2(os.path.join(class_path, f), os.path.join(out_class_path, f))\n",
    "\n",
    "    # ---------------------------\n",
    "    # Case 2: <2000 â†’ Augment\n",
    "    # ---------------------------\n",
    "    else:\n",
    "        selected_files = files[:]  # keep originals\n",
    "        for f in files:\n",
    "            shutil.copy2(os.path.join(class_path, f), os.path.join(out_class_path, f))\n",
    "\n",
    "        needed = TARGET_SIZE - total\n",
    "        print(f\"  Augmenting {needed} images...\")\n",
    "\n",
    "        for ds, imgs in dataset_groups.items():\n",
    "            ratio = len(imgs) / total\n",
    "            k = round(ratio * needed)\n",
    "            for i in range(k):\n",
    "                src_file = random.choice(imgs)\n",
    "                img = Image.open(os.path.join(class_path, src_file)).convert(\"RGB\")\n",
    "                aug_img = augment(img)\n",
    "                aug_name = f\"{os.path.splitext(src_file)[0]}_aug{i}.jpg\"\n",
    "                aug_img.save(os.path.join(out_class_path, aug_name))\n",
    "                selected_files.append(aug_name)\n",
    "\n",
    "        # Fix rounding mismatch\n",
    "        if len(selected_files) > TARGET_SIZE:\n",
    "            selected_files = selected_files[:TARGET_SIZE]\n",
    "\n",
    "    # ---------------------------\n",
    "    # After distribution\n",
    "    # ---------------------------\n",
    "    after_counts = Counter([get_dataset_name(f) for f in selected_files])\n",
    "    print_distribution(\"After processing\", after_counts, len(selected_files))\n",
    "\n",
    "print(\"\\nâœ… Balanced dataset (all classes = 2000 images) created at:\", output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
